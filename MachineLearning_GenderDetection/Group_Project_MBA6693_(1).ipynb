{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Final Project on MBA "
      ],
      "metadata": {
        "id": "RBtFpoMRgwXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gender Detection on Celeb Faces \n"
      ],
      "metadata": {
        "id": "NNDoqgoBgl-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Stage 1: Import the libraries\n"
      ],
      "metadata": {
        "id": "MPYB77OvhNQJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIVnfkHDjG2Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, Activation, GlobalAveragePooling2D\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 2: Import dataset"
      ],
      "metadata": {
        "id": "Ej4kwnL2pJB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "jzdDR4K1javM",
        "outputId": "bea0f115-796c-496c-bdd3-f842a706b028",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download jessicali9530/celeba-dataset\n",
        "! unzip celeba-dataset.zip"
      ],
      "metadata": {
        "id": "UI3-DKWfjvim",
        "outputId": "e0a20b8e-2036-4711-b8e8-aa5f07525bcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n",
            "unzip:  cannot find or open celeba-dataset.zip, celeba-dataset.zip.zip or celeba-dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Stage2i: Unzip the dataset imported"
      ],
      "metadata": {
        "id": "-ThZeMGWrrRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "! unzip celeba-dataset.zip"
      ],
      "metadata": {
        "id": "FWfy04jdj1k0",
        "outputId": "ad401225-d0c0-46e4-f49b-21ea85feae36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open celeba-dataset.zip, celeba-dataset.zip.zip or celeba-dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Stage 3: Data Exploration"
      ],
      "metadata": {
        "id": "nV51PUh3r24B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3i: Set Variables & replace all negative values to Zero\n"
      ],
      "metadata": {
        "id": "RS7pAiejC8fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = 'img_align_celeba/img_align_celeba/'\n",
        "ATTRIBUTE_PATH = 'list_attr_celeba.csv'\n",
        "PARTITION_PATH = 'list_eval_partition.csv'\n",
        "\n",
        "EXAMPLE_PIC = DATA_PATH + '000001.jpg'\n",
        "IMG_WIDTH = 178\n",
        "IMG_HEIGHT = 218\n",
        "\n",
        "TRAINING_SAMPLES = 10000\n",
        "VALIDATION_SAMPLES = 1000\n",
        "TEST_SAMPLES = 1000\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 20\n",
        "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)"
      ],
      "metadata": {
        "id": "ys6ph083kDq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list_attr_celeba.csv\n",
        "attr_df = pd.read_csv(ATTRIBUTE_PATH, index_col='image_id')\n",
        "attr_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "He9hiaETkjdE",
        "outputId": "923678ec-5bb3-4300-ce37-34e15c3239cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e3e8b506411d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# list_attr_celeba.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mattr_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATTRIBUTE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mattr_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_date_conversions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# maybe create a mi on the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_make_index\u001b[0;34m(self, data, alldata, columns, indexnamerow)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_complex_date_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_simple_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_complex_date_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_get_simple_index\u001b[0;34m(self, data, columns)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0mto_remove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36mix\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Index {col} invalid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mto_remove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Index image_id invalid"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attr_df.replace(to_replace=-1, value=0, inplace=True)\n",
        "attr_df.head()"
      ],
      "metadata": {
        "id": "DeCcDAclknXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3ii: Print out Attributes in the dataset"
      ],
      "metadata": {
        "id": "ZL0RChkAYvBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attributes\n",
        "print('Attributes:')\n",
        "for i, j in enumerate(attr_df.columns):\n",
        "    print('    {:02d}: {}'.format(i,j))"
      ],
      "metadata": {
        "id": "vu5MDcFRkng6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gender distribution\n",
        "plt.title('Gender Distribution')\n",
        "sns.countplot(y = 'Male', data=attr_df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HaKFl2p2k3da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting an example\n",
        "img = load_img(EXAMPLE_PIC)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kl7HCceYk51S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stage 4: Training, Testing and Validation"
      ],
      "metadata": {
        "id": "CI_nskgUgFWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### list_eval_partition.csv"
      ],
      "metadata": {
        "id": "0rxEWHZhmdko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parti_df = pd.read_csv(PARTITION_PATH, index_col='image_id')\n",
        "parti_df.head()"
      ],
      "metadata": {
        "id": "PcnYQf7ak8_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Partitions"
      ],
      "metadata": {
        "id": "t2XZjBT2mYtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parti_df.value_counts()"
      ],
      "metadata": {
        "id": "SS-nj5wwj2Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Joining csv"
      ],
      "metadata": {
        "id": "euIj_igrmUrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_df = attr_df[['Male']].join(parti_df)\n",
        "sampling_df.head()"
      ],
      "metadata": {
        "id": "QcZ6KHKxlEmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling of the dataset"
      ],
      "metadata": {
        "id": "LIdRTJ_nmh_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_reshape_img(filename):\n",
        "    img = load_img(filename)\n",
        "    img_array = img_to_array(img)/255\n",
        "    img_array = img_array.reshape((1,) + img_array.shape)\n",
        "    return img_array\n",
        "    \n",
        "\n",
        "def sampling(partition, sample_size, sampling_df):\n",
        "    parti_mask = sampling_df['partition'] == partition\n",
        "    male_mask = sampling_df['Male'] == 1\n",
        "    female_mask = sampling_df['Male'] == 0\n",
        "    sampled_df = pd.concat([\n",
        "        sampling_df[parti_mask & male_mask].sample(sample_size//2),\n",
        "        sampling_df[parti_mask & female_mask].sample(sample_size//2)\n",
        "    ])\n",
        "    \n",
        "    if partition != 2:\n",
        "        x = np.array([load_reshape_img(DATA_PATH + filename) for filename in sampled_df.index])\n",
        "        x = x.reshape(x.shape[0], 218, 178, 3)\n",
        "        y = np_utils.to_categorical(sampled_df['Male'],2)\n",
        "    else:\n",
        "        x = []\n",
        "        y = []\n",
        "        for index, target in sampled_df.iterrows():\n",
        "            im = cv2.imread(DATA_PATH + index) # return BGR\n",
        "            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0 # convert it to RGB for consistency\n",
        "            im = np.expand_dims(im, axis =0)\n",
        "            x.append(im)\n",
        "            y.append(target['Male'])\n",
        "            \n",
        "    return x, y"
      ],
      "metadata": {
        "id": "VftGnCxElFzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting of the dataset"
      ],
      "metadata": {
        "id": "vWs-5hremzUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train, y_train = sampling(0, TRAINING_SAMPLES, sampling_df)\n",
        "x_valid, y_valid = sampling(1, VALIDATION_SAMPLES, sampling_df)\n",
        "x_test, y_test = sampling(2, TEST_SAMPLES, sampling_df)"
      ],
      "metadata": {
        "id": "4JkcaNQylOjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Augmentation to get rid of overfitting"
      ],
      "metadata": {
        "id": "KYVb74gLnRTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_datagen.fit(x_train)\n",
        "\n",
        "train_generator = train_datagen.flow(x_train, y_train,batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "vi5-ZdYxlwF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stage 5: Modelling\n"
      ],
      "metadata": {
        "id": "uu3NvS9wnYeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build a Model"
      ],
      "metadata": {
        "id": "l6xdpsmfnsgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), input_shape = INPUT_SHAPE, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout(rate = 0.5))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout(rate = 0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate = 0.5))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate = 0.5))\n",
        "\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Gvk-qbj8l0e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Compile the Model"
      ],
      "metadata": {
        "id": "6sjmKBhCnhAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "BG45-WhVl4Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpointer = ModelCheckpoint(filepath='model.h5', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "MJKuFN4Sl-eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fit the Model"
      ],
      "metadata": {
        "id": "hH4xFL2En0OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = (x_valid, y_valid),\n",
        "    steps_per_epoch= TRAINING_SAMPLES/BATCH_SIZE,\n",
        "    epochs= 20,\n",
        "    callbacks=[checkpointer],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "4NeJxSIFmAni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot loss function value using epochs"
      ],
      "metadata": {
        "id": "KJ_eJnLDoNsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18, 4))\n",
        "plt.plot(hist.history['loss'], label = 'train')\n",
        "plt.plot(hist.history['val_loss'], label = 'valid')\n",
        "plt.legend()\n",
        "plt.title('Loss Function')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bhoPb-Hrv8Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot accuracy using epochs"
      ],
      "metadata": {
        "id": "yF3d4PdHoacu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18, 4))\n",
        "plt.plot(hist.history['accuracy'], label = 'train')\n",
        "plt.plot(hist.history['val_accuracy'], label = 'valid')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d0gT1Ev9mFHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Evaluation "
      ],
      "metadata": {
        "id": "VvuD03knof3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('model.h5')\n",
        "predictions = [np.argmax(model.predict(image)) for image in x_test]\n",
        "accuracy = 100 * np.sum(np.array(predictions)==y_test) / len(predictions)\n",
        "f1 = f1_score(y_test, predictions)\n",
        "\n",
        "print('Accuracy: {:.4f}'.format(accuracy))\n",
        "print('F1 score: {:.4f}'.format(f1))"
      ],
      "metadata": {
        "id": "RbIyJ_7YwBKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dictionary to name the prediction"
      ],
      "metadata": {
        "id": "8dWmR318owBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gender_target = {0: 'Female'\n",
        "                , 1: 'Male'}\n",
        "\n",
        "def img_to_display(filename):\n",
        "    # inspired on this kernel:\n",
        "    # https://www.kaggle.com/stassl/displaying-inline-images-in-pandas-dataframe\n",
        "    # credits to stassl :)\n",
        "    \n",
        "    i = Image.open(filename)\n",
        "    i.thumbnail((200, 200), Image.LANCZOS)\n",
        "    \n",
        "    with BytesIO() as buffer:\n",
        "        i.save(buffer, 'jpeg')\n",
        "        return base64.b64encode(buffer.getvalue()).decode()\n",
        "    \n",
        "\n",
        "def display_result(filename, prediction, target):\n",
        "    gender = 'Male'\n",
        "    gender_icon = \"https://png.pngtree.com/png-clipart/20190705/original/pngtree-man-avatar-icon-professional-man-character-png-image_4356027.jpg\"\n",
        "        \n",
        "    if prediction[1] <= 0.5:\n",
        "        gender_icon = \"https://png.pngtree.com/png-clipart/20190614/original/pngtree-female-avatar-vector-icon-png-image_3725439.jpg\"\n",
        "        gender = 'Female'\n",
        "            \n",
        "    display_html = '''\n",
        "    <div style=\"overflow: auto;  border: 2px solid #D8D8D8;\n",
        "        padding: 5px; width: 480px;\" >\n",
        "        <img src=\"data:image/jpeg;base64,{}\" style=\"float: left;\" width=\"200\" height=\"200\">\n",
        "        <div style=\"padding: 10px 0px 0px 20px; overflow: auto;\">\n",
        "            <img src=\"{}\" style=\"float: left;\" width=\"40\" height=\"40\">\n",
        "            <h3 style=\"margin-left: 50px; margin-top: 2px;\">Prediction: {}</h3>\n",
        "            <p style=\"margin-left: 50px; margin-top: -6px; font-size: 12px\">{} probability</p>\n",
        "            <p style=\"margin-left: 50px; margin-top: -16px; font-size: 12px\">Real gender: {}</p>\n",
        "        </div>\n",
        "    </div>\n",
        "    '''.format(img_to_display(filename)\n",
        "               , gender_icon\n",
        "               , gender\n",
        "               , \"{0:.2f}%\".format(round(max(prediction)*100,2))\n",
        "               , gender_target[target]\n",
        "               , filename.split('/')[-1]\n",
        "               )\n",
        "\n",
        "    display(HTML(display_html))"
      ],
      "metadata": {
        "id": "is9DUl98oGdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_prediction(filename):\n",
        "\n",
        "      im = cv2.imread(filename)\n",
        "      im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (178, 218)).astype(np.float32) / 255.0\n",
        "      im = np.expand_dims(im, axis =0)\n",
        "      \n",
        "      # prediction\n",
        "      result = model.predict(im)\n",
        "      prediction = np.argmax(result)\n",
        "      \n",
        "      return result"
      ],
      "metadata": {
        "id": "vDRpUBx_pLA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Display prediction result"
      ],
      "metadata": {
        "id": "pAAzQJCuo7aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "%matplotlib inline\n",
        "#select random images of the test partition\n",
        "df_to_test = sampling_df[(sampling_df['partition'] == 2)].sample(10)\n",
        "\n",
        "for index, target in df_to_test.iterrows():\n",
        "    result = gender_prediction(DATA_PATH + index)\n",
        "    \n",
        "    #display result\n",
        "    display_result(DATA_PATH + index, result[0], target['Male'])"
      ],
      "metadata": {
        "id": "G7BZkVP9pLMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Report Analysis**"
      ],
      "metadata": {
        "id": "E_g1ooMipN8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Image identification is one of Machine Learning's many uses; it may help with security, item detection, face detection, healthcare, and entertainment, among other things. Because this application has such a large potential to benefit our society, it's critical to identify new applications for it, improve present approaches, and gain more accurate and meaningful insights from it.\n",
        "\n",
        "##Data Description\n",
        "1.   202,599 number of face images of various celebrities\n",
        "2.   10,177 unique identities, but names of identities are not given\n",
        "3.   40 binary attribute annotations per image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4uXMDYsfPk12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In this study, we used a CNN-based Machine Learning Algorithm to determine if a celebrity is male or female based on the given dataset. This dataset was useful for recognising facial attributes such as people with dark or wavy hair and are smiling. "
      ],
      "metadata": {
        "id": "vEMYGdTtpZWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Accuracy Result\n",
        "\n",
        "# On the Train dataset, we ran 20 epochs and had the greatest gender prediction accuracy of 89.6%. On the Validation dataset, we achieved a 95.1% accuracy on the 19th epoch and saw a reduction as it approached the 20th epoch, with an accuracy of 92.6%.\n",
        "\n",
        "\n",
        "#The model performed well on the train dataset in general, with a growing accuracy score at each epoch and a lowering loss function. The train dataset shows that the better the accuracy, the lesser the loss.\n",
        "\n",
        "#While on the Validation set, it began with an accuracy level of 80% and was unstable until it reached the 11th epoch and maintained a >90% accuracy. The loss on the validation set likewise fluctuated, ranging from an 83% loss to a 19.7% loss.\n"
      ],
      "metadata": {
        "id": "GdUCVEatEZKF"
      }
    }
  ]
}